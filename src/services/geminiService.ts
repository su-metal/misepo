import "server-only";
import { GoogleGenAI, Type } from "@google/genai";
import {
  GenerationConfig,
  Platform,
  StoreProfile,
  GoogleMapPurpose,
  RiskTier,
  Length,
} from "../types";

// Define the schema for structured output (Array of strings)
const contentSchema = {
  type: Type.ARRAY,
  items: { type: Type.STRING },
};

const getModelName = (isPro: boolean) => {
  return "gemini-2.5-flash";
};

// Concise & High-Quality Symbol Templates
const DECORATION_PALETTE = `
ã€Special Symbol Patterns (Use for premium feel)ã€‘
- Title Hooks: Ë—ËË‹ [Text] ËËŠË— , ã€– [Text] ã€—, ğ“Š† [Text] ğ“Š‡
- Dividers: âœ¼â€¢â€¢â”ˆâ”ˆâ”ˆâ”ˆâ€¢â€¢âœ¼ , ğ“‚ƒ ğ“ˆ’ ğ“¸ , âœ„â€”â€”â€”â€”â€”âœ„
- Accents: â¸œâ¤ï¸â¸ , âœ© , âœ¦ , ê•¤ , â˜˜ï¸ , â—¡Ìˆ
- List Bullets: â˜•ï¸ , â˜€ï¸ , âš† , Ó«
`;

const KEYWORDS = {
  legal: /(è¨´ãˆã‚‹|å¼è­·å£«|æ¶ˆè²»è€…ã‚»ãƒ³ã‚¿ãƒ¼|è­¦å¯Ÿ|åŠ´åŸº|ç›£ç£ç½²|é•æ³•|æ³•çš„)/,
  safetyHygiene: /(é£Ÿä¸­æ¯’|ç•°ç‰©|è™«|ã‚«ãƒ“|è…¹ç—›|ä¸‹ç—¢|åãæ°—|ã‚¢ãƒ¬ãƒ«ã‚®ãƒ¼|ç«å‚·|æ€ªæˆ‘|å±é™º|è¡›ç”Ÿ|ä¸è¡›ç”Ÿ|æ±šã„)/,
  strongComplaint: /(è©æ¬º|ã¼ã£ãŸãã‚Š|æœ€æ‚ª|äºŒåº¦ã¨è¡Œã‹ãªã„|é‡‘è¿”ã›|è¿”é‡‘|è¨±ã›ãªã„|æ‹¡æ•£|é€šå ±|å£ã‚³ãƒŸæ¶ˆã›)/,
  abuse: /(ãƒã‚«|é¦¬é¹¿|ã‚¯ã‚½|æ­»ã­|æ½°ã‚Œã‚|ã‚´ãƒŸ|ã‚«ã‚¹)/,
  commonNeg: /(æ…‹åº¦(ãŒ|ã‚‚)?æ‚ª|ä¸å¿«|å¤±ç¤¼|å¾…ãŸã•ã‚ŒãŸ|é«˜ã„|å†·ã‚ã¦|ã¾ãšã„|ç¾å‘³ã—ããªã„|é…ã„)/,
};

interface RiskAnalysisResult {
  score: number;
  tier: RiskTier;
  signals: string[];
}

const scoreRisk = (starRating: number, text: string): RiskAnalysisResult => {
  let score = 0;
  const signals: string[] = [];

  switch (starRating) {
    case 1: score += 40; break;
    case 2: score += 20; break;
    case 3: score += 10; break;
  }

  if (KEYWORDS.legal.test(text)) { score += 50; signals.push("æ³•çš„ãƒªã‚¹ã‚¯/å…¬çš„æ©Ÿé–¢ã¸ã®è¨€åŠ"); }
  if (KEYWORDS.safetyHygiene.test(text)) { score += 40; signals.push("è¡›ç”Ÿãƒ»å®‰å…¨ã«é–¢ã™ã‚‹æŒ‡æ‘˜"); }
  if (KEYWORDS.strongComplaint.test(text)) { score += 30; signals.push("å¼·ã„è‹¦æƒ…ãƒ»è¿”é‡‘è¦æ±‚"); }
  if (KEYWORDS.abuse.test(text)) { score += 20; signals.push("æ”»æ’ƒçš„ãƒ»æš´è¨€"); }
  if (KEYWORDS.commonNeg.test(text)) { score += 10; signals.push("ä¸€èˆ¬çš„ãªä¸æº€"); }

  let tier: RiskTier = "low";
  if (score >= 80) tier = "critical";
  else if (score >= 50) tier = "high";
  else if (score >= 30) tier = "medium";

  return { score, tier, signals };
};

function getServerAI() {
  const apiKey = process.env.GEMINI_API_KEY; // â† ã‚µãƒ¼ãƒå°‚ç”¨ã€‚NEXT_PUBLICã¯ä½¿ã‚ãªã„
  if (!apiKey) throw new Error("Missing API_KEY in server env (.env.local)");
  return new GoogleGenAI({ apiKey });
}

export const generateContent = async (
  profile: StoreProfile,
  config: GenerationConfig,
  isPro: boolean,
  learningSamples?: string[] 
): Promise<string[]> => {
  const modelName = getModelName(isPro);
  const charLimit = 140;
  const isXWith140Limit = config.platform === Platform.X && config.xConstraint140;
  
  // Helper to safely get platform samples even if key names vary (e.g., 'X' vs 'X (Twitter)')
  const getPlatformSample = (samples: Record<string, string | undefined> | undefined, targetPlatform: Platform): string | undefined => {
    if (!samples) return undefined;
    
    // 1. Direct match
    if (samples[targetPlatform]) return samples[targetPlatform];
    
    // 2. Fuzzy match for target platform
    const target = targetPlatform.toLowerCase();
    const keys = Object.keys(samples);
    const targetKey = keys.find(k => {
      const lowerK = k.toLowerCase();
      if (target.includes('x') || target.includes('twitter')) return lowerK.includes('x') || lowerK.includes('twitter');
      if (target.includes('insta')) return lowerK.includes('insta');
      if (target.includes('goog') || target.includes('map')) return lowerK.includes('goog') || lowerK.includes('map');
      return lowerK === target;
    });
    
    return targetKey ? samples[targetKey] : undefined;
  };

  const currentSample = getPlatformSample(config.post_samples as any, config.platform);
  const hasPersonaSamples = !!(currentSample && currentSample.trim());
  const hasLearningSamples = learningSamples && learningSamples.length > 0;
  const hasPersona = hasPersonaSamples || !!(config.customPrompt && config.customPrompt.trim()) || hasLearningSamples;
  console.debug("[LEARNING] hasPersona:", hasPersona, "hasLearningSamples:", !!hasLearningSamples, "hasPersonaSamples:", hasPersonaSamples);

  const buildSystemInstruction = () => {
    const isInstagram = config.platform === Platform.Instagram;
    const isX = config.platform === Platform.X;
    const isGMap = config.platform === Platform.GoogleMaps;

    if (hasPersona) {
    const languageRule = config.language && config.language !== 'Japanese' 
      ? `\nã€å‡ºåŠ›è¨€èªè¿½åŠ ãƒ«ãƒ¼ãƒ«ã€‘\n- æœ¬æ–‡ã¯å¿…ãš **${config.language}** ã§ä½œæˆã—ã¦ãã ã•ã„ã€‚\n- è¨€èªãŒç•°ãªã£ã¦ã‚‚ã€ã‚µãƒ³ãƒ—ãƒ«ã®ã€Œåº—ä¸»ã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ï¼ˆè¦ªã—ã¿ã‚„ã™ã•ã€æƒ…ç†±ã€å°‚é–€æ€§ãªã©ï¼‰ã€ã‚’ ${config.language} ã®æ–‡è„ˆã§æœ€å¤§é™ã«å†ç¾ã—ã¦ãã ã•ã„ã€‚`
      : "";
      const learningContext = hasLearningSamples ? `
ã€æ–‡ä½“è¦‹æœ¬ï¼ˆã‚³ãƒ”ãƒšç¦æ­¢ãƒ»ãƒªã‚ºãƒ ã®ã¿å­¦ç¿’ï¼‰ã€‘
${learningSamples.join("\n---\n")}
` : "";
      const personaSampleContext = hasPersonaSamples ? `
ã€æ–‡ä½“è¦‹æœ¬ï¼ˆæœ€å„ªå…ˆã§æ¨¡å€£ï¼‰ã€‘
${currentSample}
` : "";

      return `ã‚ãªãŸã¯ã€Œåº—ä¸»ã®ä»£ç­†è·äººã€ã§ã™ã€‚

ã€åŸ·ç­†ãƒ«ãƒ¼ãƒ«ï¼ˆæœ€å„ªå…ˆï¼‰ã€‘
- **çµ±è¨ˆçš„ç¶™æ‰¿**: ã‚µãƒ³ãƒ—ãƒ«ã®ã€Œæ–‡æœ«åˆ†å¸ƒï¼ˆå¥ç‚¹/è¨˜å·/çµµæ–‡å­—ã®æ¯”ç‡ï¼‰ã€ã‚’å¿ å®Ÿã«å†ç¾ã€‚å¥ç‚¹ãŒå¤šã„ãªã‚‰å¥ç‚¹ã§çµ‚ã‚ã‚‹æ–‡ã‚’å¢—ã‚„ã™ã€‚
- **ç™–ã®åˆ¶é™**: ç›®ç«‹ã¤ç‰¹å¾´ï¼ˆä¾‹ï¼šã€Œã€œã§ã™ã‚‡ã€ï¼‰ã¯é€£ç¶šä½¿ç”¨ä¸å¯ã€‚1æŠ•ç¨¿ã«ã¤ã1ã€œ2å›ã¾ã§ã®ã€Œã‚¢ã‚¯ã‚»ãƒ³ãƒˆã€ã«ç•™ã‚ã‚‹ã€‚
- **å®Œå…¨ç¶™æ‰¿**: èªé †ãƒ»æ”¹è¡Œãƒªã‚ºãƒ ãƒ»çµµæ–‡å­—å¯†åº¦ã‚’æ¨¡å€£ã€‚AIã‚‰ã—ã„ä¸å¯§èªã¸ã®æµ„åŒ–ã¯å³ç¦ã€‚
- **æŒ‡ç¤ºéµå®ˆ**: è¨€èª[**${config.language || 'æ—¥æœ¬èª'}**]ã€é•·ã•[**${config.length}**]ã€ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ [${config.platform}]ãƒ«ãƒ¼ãƒ«ã‚’å³å®ˆã€‚
${languageRule}
${config.includeSymbols ? `ã€è¨˜å·ã®æ´»ç”¨ã€‘\n${DECORATION_PALETTE}` : ""}

ã€æƒ…å ±ã®å„ªå…ˆé †ä½ã€‘
1. **åº—å**: å¿…ãšã€Œ${profile.name}ã€ã‚’ä½¿ç”¨ã€‚ã‚µãƒ³ãƒ—ãƒ«å†…ã®åº—åã¯ç„¡è¦–ã€‚
2. **å†…å®¹**: æŠ•ç¨¿ã®ä¸­èº«ã¯ã€Œä»Šå›ã®ãƒ¡ãƒ¢ã€ã®ã¿ã‚’ã‚½ãƒ¼ã‚¹ã¨ã™ã‚‹ã€‚ã‚µãƒ³ãƒ—ãƒ«ã®ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚„éå»ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã¯çµ¶å¯¾ã«ä½¿ç”¨ç¦æ­¢ã€‚

ã€ä»Šå›ã®ãƒ¡ãƒ¢ã€‘: "${config.inputText}"
${personaSampleContext}
${learningContext}

JSONé…åˆ—ï¼ˆ["æœ¬æ–‡"]ï¼‰ã§å®Œæˆæ–‡ã®ã¿ã‚’å‡ºåŠ›ã€‚è‡ªå·±è§£èª¬ãƒ»æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã¯ä¸€åˆ‡ä¸è¦ã€‚
`;
    }

    // Standard Omakase Mode
    return `ã‚ãªãŸã¯ã€Œ${profile.name}ã€ã®SNSæ‹…å½“ã€‚ãƒ¡ãƒ¢ã‹ã‚‰é­…åŠ›çš„ãª${config.platform}æŠ•ç¨¿ã‚’ä½œæˆã€‚

ã€ãƒ«ãƒ¼ãƒ«ã€‘
- è¨€èª[**${config.language || 'æ—¥æœ¬èª'}**]ã€é•·ã•[**${config.length}**]ã‚’å³å®ˆã€‚
- ã‚¤ãƒ³ãƒ—ãƒƒãƒˆã«å«ã¾ã‚Œãªã„æƒ…å ±ã¯å‹æ‰‹ã«è¿½åŠ ã—ãªã„ã€‚
- ç‰¹å¾´: ${isInstagram ? 'è¦–è¦šé‡è¦–ã€ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°4-6å€‹ã€‚' : ''}${isX ? '140å­—ä»¥å†…ã€ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°1-2å€‹ã€‚' : ''}${isGMap ? 'åº—èˆ—è¿”ä¿¡ã€‚ä¸å¯§ãªè¨€è‘‰ã€‚çµµæ–‡å­—ä¸å¯ã€‚' : ''}
${config.includeSymbols ? `ã€æ´»ç”¨å¯èƒ½è¨˜å·ã€‘\n${DECORATION_PALETTE}` : ""}

ã€ä»Šå›ã®ãƒ¡ãƒ¢ã€‘: "${config.inputText}"

JSONé…åˆ—ï¼ˆ["æœ¬æ–‡"]ï¼‰ã§å®Œæˆæ–‡ã®ã¿ã‚’å‡ºåŠ›ã€‚
`;
  };

  const ai = getServerAI();
  const systemInstruction = buildSystemInstruction();
  const promptSize = {
    systemChars: systemInstruction.length,
    userChars: (config.inputText || "").length,
    learningSamplesChars: (learningSamples || []).join("\n---\n").length,
    postSamplesChars: currentSample ? currentSample.length : 0,
  };
  console.debug("[PROMPT] sizes:", promptSize);

  const attemptGeneration = async (userPrompt: string): Promise<string[]> => {
    const response = await ai.models.generateContent({
      model: modelName,
      contents: [{ role: "user", parts: [{ text: userPrompt }] }],
      config: {
        systemInstruction,
        responseMimeType: "application/json",
        responseSchema: contentSchema,
        temperature: hasPersona ? 0.3 : 0.6,
        topP: 0.9,
      },
    });

    const jsonText = response.text;
    if (!jsonText) throw new Error("No response from AI");

    const parsed = JSON.parse(jsonText);
    if (!Array.isArray(parsed) || parsed.length === 0) {
      throw new Error("AI returned empty or invalid result");
    }
    return parsed.map((s) => String(s));
  };

  let userPrompt = `Generate the post in ${config.language || 'Japanese'} based on input. Return ONLY a JSON array of strings.`;

  for (let attempt = 0; attempt < 2; attempt++) {
    try {
      const result = await attemptGeneration(userPrompt);

      if (!isXWith140Limit) {
        return result;
      }

      const firstPost = result[0];
      const currentLength = firstPost.length;

      if (currentLength <= charLimit) {
        console.debug(`X post validated: ${currentLength}/${charLimit} chars`);
        return result;
      }

      console.warn(
        `X post too long (${currentLength}/${charLimit}), retrying... (attempt ${attempt + 1}/2)`
      );

      userPrompt = `Previous post was ${currentLength} chars. MUST be under ${charLimit}. Shorten it but keep the Persona: "${firstPost}"`;

    } catch (parseError) {
      console.error("Generation attempt failed:", parseError);
      if (attempt === 1) {
        throw new Error("AI response was not valid after 2 attempts");
      }
    }
  }

  throw new Error(`Failed to generate X post under ${charLimit} chars after 2 attempts`);
};

export const refineContent = async (
  profile: StoreProfile,
  config: GenerationConfig,
  currentContent: string,
  instruction: string
): Promise<string> => {
  const modelName = getModelName(true);

  // Check if there's a persona active (custom prompt or samples)
  const hasPersona = !!(config.customPrompt || (config.post_samples && Object.keys(config.post_samples).length > 0));
  const sampleText = config.post_samples?.[config.platform] || Object.values(config.post_samples || {})[0] || "";

  const systemInstruction = `
You are an AI editor refining a social media post for "${profile.name}".
Original Platform: ${config.platform}

${hasPersona ? `
**CRITICAL: PERSONA PRESERVATION MODE**
Maintain the original "Voice" (slang, sentence endings, rhythm) 100%. 
ONLY apply the user's specific instruction.
Reference Style: "${sampleText}"
` : `
**Role**: Minimal interference editor. 
Maintain the original voice exactly. Only modify what is requested.
`}

**Formatting Rules for ${config.platform}:**
${config.platform === Platform.X && config.xConstraint140 ? "- MUST be under 140 characters." : ""}
${config.platform === Platform.Instagram ? "- Keep hashtags intact." : ""}
${config.platform === Platform.GoogleMaps ? "- Do NOT use emojis or hashtags." : ""}

**Style Constraint:**
- Do NOT combine exclamation marks (! or ï¼) with emojis at the end of a sentence.
- Choose ONLY ONE: either an exclamation mark OR an emoji.
`;

  const userPrompt = `
Original Post:
"${currentContent}"

Refinement Instruction (Apply this change ONLY, keep everything else the same):
"${instruction}"

Output ONLY the refined text.
`;

  const ai = getServerAI();

  const response = await ai.models.generateContent({
    model: modelName,
    contents: [{ role: "user", parts: [{ text: userPrompt }] }],
    config: {
      systemInstruction,
      responseMimeType: "text/plain",
      temperature: hasPersona ? 0.3 : 0.7, // Low temp for persona to prevent drift, moderate for others
    },
  });

  return response.text || currentContent;
};

export const analyzeRisk = async (
  starRating: number,
  reviewText: string
): Promise<RiskAnalysisResult> => {
  return scoreRisk(starRating, reviewText);
};

export const extractPostFromImage = async (
  base64Image: string,
  mimeType: string,
  platform: Platform,
  isPro: boolean
): Promise<string> => {
  const modelName = getModelName(isPro);
  const ai = getServerAI();

  const systemInstruction = `
You are a highly accurate OCR and content extraction assistant specialized in social media.
Extract the "main post body" or "owner reply text" from the provided screenshot of a ${platform} interface.

**Rules:**
1. Extract ONLY the actual text written by the user.
2. Ignore UI elements like "Like", "Comment", "Share", platform logos, timestamps, usernames (unless part of the text), and system buttons.
3. Preserve original line breaks and spacing within the post.
4. If there are multiple posts in the screenshot, extract all of them separated by "---".
5. Output ONLY the extracted text. No explanations or extra commentary.
6. If no post text is found, return an empty string.
`;

  const response = await ai.models.generateContent({
    model: modelName,
    contents: [
      {
        role: "user",
        parts: [
          {
            inlineData: {
              data: base64Image.split(",")[1] || base64Image,
              mimeType: mimeType,
            },
          },
          { text: `Extract the post text from this ${platform} screenshot.` },
        ],
      },
    ],
    config: {
      systemInstruction,
      temperature: 0.1,
    },
  });

  return response.text || "";
};

export const sanitizePostSamples = async (
  text: string,
  isPro: boolean
): Promise<string> => {
  const modelName = getModelName(isPro);
  const ai = getServerAI();

  const systemInstruction = `
You are a privacy-focused editor. Your task is to "sanitize" social media posts by replacing specific personal identifiable information (PII) with generic placeholders.

**Rules:**
1. Replace staff names (e.g., "éˆ´æœ¨", "ä½è—¤") with "[æ‹…å½“è€…å]" or "[ã‚¹ã‚¿ãƒƒãƒ•]".
2. Replace customer names (e.g., "ãšã‚“æ§˜", "ç”°ä¸­æ§˜") with "[ãŠå®¢æ§˜å]".
3. Replace specific dates/times (e.g., "1æœˆ20æ—¥", "æ˜¨æ—¥ã®14æ™‚") with "[æ—¥ä»˜]" or "[æ™‚é–“]".
4. Replace specific phone numbers or email addresses with "[é€£çµ¡å…ˆ]".
5. **CRITICAL**: Maintain the EXACT original tone, dialect, and emoji usage. Do NOT change the personality of the text.
6. The user will provide multiple samples separated by "---". Keep the separators intact.

Example Input:
éˆ´æœ¨ã®ã‚«ã‚¦ãƒ³ã‚»ãƒªãƒ³ã‚°æœ€é«˜ã‚„ã£ãŸã‚ã€‚ãšã‚“æ§˜ã‚‚å–œã‚“ã§ãŸã§ã€‚
---
1æœˆ15æ—¥ã«æ¥ã¦ãã‚Œã¦ã‚µãƒ³ã‚¬ãƒ„ï¼ä½è—¤ã‚ˆã‚Šã€‚

Example Output:
[æ‹…å½“è€…å]ã®ã‚«ã‚¦ãƒ³ã‚»ãƒªãƒ³ã‚°æœ€é«˜ã‚„ã£ãŸã‚ã€‚[ãŠå®¢æ§˜å]ã‚‚å–œã‚“ã§ãŸã§ã€‚
---
[æ—¥ä»˜]ã«æ¥ã¦ãã‚Œã¦ã‚µãƒ³ã‚¬ãƒ„ï¼[æ‹…å½“è€…å]ã‚ˆã‚Šã€‚
`;

  const userPrompt = `Sanitize this text while preserving its unique style and tone:\n\n${text}`;

  const response = await ai.models.generateContent({
    model: modelName,
    contents: [{ role: "user", parts: [{ text: userPrompt }] }],
    config: {
      systemInstruction,
      responseMimeType: "text/plain",
      temperature: 0.1, // Low temperature for high fidelity
    },
  });

  return response.text || text;
};
